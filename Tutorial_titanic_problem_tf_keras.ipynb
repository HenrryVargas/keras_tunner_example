{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial titanic_problem_tf.keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python361064bittensorflowgpuconda2ec8b511c5f643f291e3a6ecb82f995f",
      "display_name": "Python 3.6.10 64-bit ('tensorflow-gpu': conda)"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "outputs": [],
      "source": [
        "<a href=\"https://colab.research.google.com/github/senkmp/titanic-tf.keras/blob/master/Tutorial_titanic_problem_tf_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "oI7knaZK8jnd"
      },
      "outputs": [],
      "source": [
        "# Train tf.keras model using feature coulmns "
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "5yet5I-fme3p"
      },
      "outputs": [],
      "source": [
        "In this tutorial, we will see how to use tf.keras model to classify structured data (pandas dataframe)  with creating an input pipe line using feature columns ( tf.feature_column) and tf.data.\n",
        "\n",
        "you will learn-\n",
        "\n",
        "\n",
        "* Creating different types of feature columns using tf.feature_columns\n",
        "* Creating input data function using tf.data for train, val and test set\n",
        "* Creating, compiling and training of tf.keras.model \n",
        "* Evaluating model\n",
        "* Prediction on test data\n",
        "\n",
        "## The Dataset\n",
        "\n",
        "I have used [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic/overview) from kaggle, you can [download](https://www.kaggle.com/c/3136/download-all) and find [description](https://www.kaggle.com/c/titanic/data) of dataset on kaggle. I have used google colab and hence uploaded data in google drive.\n",
        "\n",
        "## Mount google drive\n",
        "I have uploaded data on **google drive,** Learn How to use data from google drive [here](https://medium.com/ml-book/simplest-way-to-open-files-from-google-drive-in-google-colab-fae14810674)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "BspuOkXyIoWw",
        "outputId": "a9c89473-5ebe-490b-8afa-4ec5d162fc19"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "Zs0qZTKg-yc1"
      },
      "outputs": [],
      "source": [
        "# Import TensorFlow and other libraries\n",
        "I have used Tensorflow nightly version which is unstable version (aug 2019)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Requirement already satisfied: tensorflow-gpu in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (2.1.0)\nRequirement already satisfied: grpcio>=1.8.6 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow-gpu) (1.27.2)\nRequirement already satisfied: protobuf>=3.8.0 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow-gpu) (3.11.3)\nRequirement already satisfied: astor>=0.6.0 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow-gpu) (0.8.1)\nRequirement already satisfied: numpy<2.0,>=1.16.0 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow-gpu) (1.18.1)\nRequirement already satisfied: wrapt>=1.11.1 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow-gpu) (1.12.1)\nRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow-gpu) (1.4.1)\nRequirement already satisfied: google-pasta>=0.1.6 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow-gpu) (0.2.0)\nRequirement already satisfied: keras-preprocessing>=1.1.0 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow-gpu) (1.1.0)\nRequirement already satisfied: tensorflow-gpu-estimator<2.2.0,>=2.1.0rc0 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow-gpu) (2.1.0)\nRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow-gpu) (0.34.2)\nRequirement already satisfied: tensorboard<2.2.0,>=2.1.0 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow-gpu) (2.1.1)\nRequirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow-gpu) (1.14.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow-gpu) (3.2.0)\nRequirement already satisfied: keras-applications>=1.0.8 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow-gpu) (1.0.8)\nRequirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow-gpu) (1.1.0)\nRequirement already satisfied: absl-py>=0.7.0 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow-gpu) (0.9.0)\nRequirement already satisfied: gast==0.2.2 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorflow-gpu) (0.2.2)\nRequirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from protobuf>=3.8.0->tensorflow-gpu) (46.0.0.post20200309)\nRequirement already satisfied: google-auth<2,>=1.6.3 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.11.3)\nRequirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.2.1)\nRequirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.23.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.1)\nRequirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.0.0)\nRequirement already satisfied: h5py in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.10.0)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0.0)\nRequirement already satisfied: rsa<4.1,>=3.1.4 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.2.8)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.25.8)\nRequirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.9)\nRequirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2019.11.28)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.3.0)\nRequirement already satisfied: pyasn1>=0.1.3 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.0)\nERROR:root:Internal Python error in the inspect module.\nBelow is the traceback from this internal error.\n\nRequirement already satisfied: sklearn in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (0.0)\nRequirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from sklearn) (0.22.2.post1)\nRequirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\nRequirement already satisfied: scipy>=0.17.0 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\nRequirement already satisfied: numpy>=1.11.0 in c:\\programdata\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-e22090d58efa>\", line 17, in <module>\n    from tensorflow import feature_column\nImportError: cannot import name 'feature_column'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n    stb = value._render_traceback_()\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: DLL load failed: No se puede encontrar el módulo especificado.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n    return f(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\inspect.py\", line 1490, in getinnerframes\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\inspect.py\", line 1448, in getframeinfo\n    filename = getsourcefile(frame) or getfile(frame)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\inspect.py\", line 696, in getsourcefile\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\inspect.py\", line 733, in getmodule\n    if ismodule(module) and hasattr(module, '__file__'):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n    module = self._load()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n    module = _importlib.import_module(self.__name__)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 941, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\n    from . _api.v2 import audio\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n    module = self._load()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n    module = _importlib.import_module(self.__name__)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\importlib\\__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n    raise ImportError(msg)\nImportError: Traceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-e22090d58efa>\", line 17, in <module>\n    from tensorflow import feature_column\nImportError: cannot import name 'feature_column'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n    stb = value._render_traceback_()\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: DLL load failed: No se puede encontrar el módulo especificado.\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.\n"
        },
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'feature_column'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  !pip install tensorflow-gpu\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "\n",
        "\n",
        "!pip install sklearn\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IkckxD8VahOL"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "dfCp-DEn_Yw9"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess Data"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "V5d73uRWLuvf"
      },
      "outputs": [],
      "source": [
        "## Use Pandas to create a dataframe\n",
        "\n",
        "[Pandas](https://pandas.pydata.org/) is a Python library with many helpful utilities for loading and working with structured data. We will use Pandas to download the dataset from mounted google drive, and load it into a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "colab_type": "code",
        "id": "N7_n4-mbJG5I",
        "outputId": "e0db19de-c44f-43ad-ac25-a3d822ea3276"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('train.csv')\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "colab_type": "code",
        "id": "DfJwsS34JXQC",
        "outputId": "80fdd3b1-f2fc-4c45-e1af-d2715e4fe28d"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "znOOxh0KMFdw"
      },
      "outputs": [],
      "source": [
        "## Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "Kw70CXSIMOId"
      },
      "outputs": [],
      "source": [
        "### Check missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "colab_type": "code",
        "id": "zgIfUfC2Kbtf",
        "outputId": "7471dbfa-033c-4f5d-9d19-716ef5a23b9b"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "ApZ8aEfHMmbk"
      },
      "outputs": [],
      "source": [
        "### Missing value handling\n",
        "\n",
        "As you can seee that there are some missing values in 'age' , 'embark' and 'cabin'. In 'cabin' number of missing values are large hence we delete this column from data, and in 'age' we will fill missing values with mean value and in 'embark' with most frequent value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2IZp5IeSLhj9"
      },
      "outputs": [],
      "source": [
        "mean_value = round(data['Age'].mean())\n",
        "mode_value = data['Embarked'].mode()[0]\n",
        "\n",
        "value = {'Age': mean_value, 'Embarked': mode_value}\n",
        "data.fillna(value=value,inplace=True)\n",
        "\n",
        "data.dropna(axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "colab_type": "code",
        "id": "zYbAH5QzNIaQ",
        "outputId": "83b124f9-cbb5-43cb-de14-d36de377ab72"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "tBLt7eYBTg8p"
      },
      "outputs": [],
      "source": [
        "## Explore data with pandas_profiling library "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ipRMZsdSJ27S"
      },
      "outputs": [],
      "source": [
        "import pandas_profiling as pdpf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "colab_type": "code",
        "id": "E4gBkrMlKIKO",
        "outputId": "d8777821-9848-49d6-d87e-148d7baedeeb"
      },
      "outputs": [],
      "source": [
        "pdpf.ProfileReport(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "1UDmGsYH_vb1"
      },
      "outputs": [],
      "source": [
        "# Train, val, test Split\n",
        "\n",
        "We will divide data into train, validation, test data with 3:1:1 ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "colab_type": "code",
        "id": "7cpfPx9kSI5K",
        "outputId": "ed3d1aa6-690c-47b1-df20-712e54e6545f"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(data, test_size=0.2)\n",
        "train, val = train_test_split(train, test_size=0.25)\n",
        "print(len(train), 'train examples')\n",
        "print(len(val), 'validation examples')\n",
        "print(len(test), 'test examples')"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "908_JL0P_4OV"
      },
      "outputs": [],
      "source": [
        "# Input pilpe line\n",
        "\n",
        "## Create an input pipeline using tf.data\n",
        "\n",
        "Next, we will wrap the dataframes with [tf.data](https://www.tensorflow.org/guide/datasets). This will enable us  to use feature columns as a bridge to map from the columns in the Pandas dataframe to features used to train the model. If we were working with a very large CSV file (so large that it does not fit into memory), we would use tf.data to read it from disk directly. That is not covered in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "aobXv0rWSVsE"
      },
      "outputs": [],
      "source": [
        "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop('Survived')\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Zc-lGRoSSWL_"
      },
      "outputs": [],
      "source": [
        "batch_size = 32 \n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "34t2mMOQrjBR"
      },
      "outputs": [],
      "source": [
        "## Understand the input pipeline\n",
        "\n",
        "Now that we have created the input pipeline, let's call it to see the format of the data it returns. We have used a small batch size to keep the output readable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "colab_type": "code",
        "id": "dYcS3I7USjxC",
        "outputId": "e6c6974d-e61c-495b-c022-1c8ec63e2ed5"
      },
      "outputs": [],
      "source": [
        "for feature_batch, label_batch in train_ds.take(1):\n",
        "  print('Every feature:', list(feature_batch.keys()))\n",
        "  print('A batch of ages:', feature_batch['Age'])\n",
        "  print('A batch of targets:', label_batch )"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "grNDOEKFrlFx"
      },
      "outputs": [],
      "source": [
        "We can see that the dataset returns a dictionary of column names (from the dataframe) that map to column values from rows in the dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "jpJVpcgUAGSm"
      },
      "outputs": [],
      "source": [
        "## Feature columns\n",
        "\n",
        "Know more about feature columns [here](https://medium.com/ml-book/demonstration-of-tensorflow-feature-columns-tf-feature-column-3bfcca4ca5c4) "
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "-XcRchQtAGHH"
      },
      "outputs": [],
      "source": [
        "### Decide which types of features you have in data\n",
        "While data exploration you should note the types of features we have, for example, whether a feature is numerical or categorical, if it is numerical then can we categorize it into buckets or not, or if it is categorical then it should be checked how many categories are there, can we convert it into indicator columns or embedding column, are there any two feature, those can we combined to create new crossed feature. I will recommend you to read this very simplified [tutorial on feature columns](https://medium.com/ml-book/demonstration-of-tensorflow-feature-columns-tf-feature-column-3bfcca4ca5c4)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7qBXyJIhKu2F"
      },
      "outputs": [],
      "source": [
        "#numarical features\n",
        "num_c = ['Age','Fare','Parch','SibSp'] \n",
        "bucket_c  = ['Age'] #bucketized numerical feature\n",
        "\n",
        "#categorical features\n",
        "cat_i_c = ['Embarked', 'Pclass','Sex'] #indicator columns\n",
        "cat_e_c = ['Ticket'] # embedding column"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "XarZtFjd6xGh"
      },
      "outputs": [],
      "source": [
        "### Scaler function\n",
        "It is very important for numerical variables to get scaled. here I have used min-max scaling. Here we are creating a function named 'get_scal' which takes list of numerical features and  returns 'minmax' function, which will be used in tf.feature_column.numeric_column() as normalizer_fn in parameters. 'minmax' function itself takes a 'numerical' number from a particular feature and return scaled value of that number. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MA-RZuUkh3mu"
      },
      "outputs": [],
      "source": [
        "def get_scal(feature):\n",
        "  def minmax(x):\n",
        "    mini = train[feature].min()\n",
        "    maxi = train[feature].max()\n",
        "    return (x - mini)/(maxi-mini)\n",
        "  return(minmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "ca-6KKB79FN_"
      },
      "outputs": [],
      "source": [
        "### Creating feature columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "adAWWyoI9N7H"
      },
      "outputs": [],
      "source": [
        "#### Numerical Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DoUEEJ7WSkS5"
      },
      "outputs": [],
      "source": [
        "feature_columns = []\n",
        "for header in num_c:\n",
        "  scal_input_fn = get_scal(header)\n",
        "  feature_columns.append(feature_column.numeric_column(header, normalizer_fn=scal_input_fn))"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "L8rQzLha9lEn"
      },
      "outputs": [],
      "source": [
        "#### Bucketized columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "yBCSVONpTE-G"
      },
      "outputs": [],
      "source": [
        "Age = feature_column.numeric_column(\"Age\")\n",
        "# bucketized cols\n",
        "age_buckets = feature_column.bucketized_column(Age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
        "feature_columns.append(age_buckets)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "rO_pu1b3-SCs"
      },
      "outputs": [],
      "source": [
        "#### Categorical Indicator columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "y6CfmwpQUYKm"
      },
      "outputs": [],
      "source": [
        "for feature_name in cat_i_c:\n",
        "  vocabulary = data[feature_name].unique()\n",
        "  cat_c = tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)\n",
        "  one_hot = feature_column.indicator_column(cat_c)\n",
        "  feature_columns.append(one_hot)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "Z9LOMwJz-cqn"
      },
      "outputs": [],
      "source": [
        "#### Categorical Embedding columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rU-KE8xjVSgr"
      },
      "outputs": [],
      "source": [
        "for feature_name in cat_e_c:\n",
        "  vocabulary = data[feature_name].unique()\n",
        "  cat_c = tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)\n",
        "  embeding = feature_column.embedding_column(cat_c, dimension=50)\n",
        "  feature_columns.append(embeding)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "MMq_THxZ-oxX"
      },
      "outputs": [],
      "source": [
        "#### Crosed columns\n",
        "Combination of 'age' (age buckets) and 'sex'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BTcCauWXdgde"
      },
      "outputs": [],
      "source": [
        "vocabulary = data['Sex'].unique()\n",
        "Sex = tf.feature_column.categorical_column_with_vocabulary_list('Sex', vocabulary)\n",
        "\n",
        "crossed_feature = feature_column.crossed_column([age_buckets, Sex], hash_bucket_size=1000)\n",
        "crossed_feature = feature_column.indicator_column(crossed_feature)\n",
        "feature_columns.append(crossed_feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "colab_type": "code",
        "id": "y32eYPVkb_0J",
        "outputId": "c9199926-c643-4427-a50b-5a052d383d5c"
      },
      "outputs": [],
      "source": [
        "print('Total number of feature coumns: ',len(feature_columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "GfbmPf6OAOCb"
      },
      "outputs": [],
      "source": [
        "# Create, compile and train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "bmRsU9iI_djv"
      },
      "outputs": [],
      "source": [
        "### Create a feature layer\n",
        "Now that we have defined our feature columns, we will use a [DenseFeatures](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/DenseFeatures) layer to input them to our Keras model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "I9AlMTTpSyj9"
      },
      "outputs": [],
      "source": [
        "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "ivC3uG7nAc9R"
      },
      "outputs": [],
      "source": [
        "#### tf.keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "colab_type": "code",
        "id": "leptwzjqXJDa",
        "outputId": "5c6d1511-8193-4827-b27e-dffa66e8dc38"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "  feature_layer,\n",
        "  layers.Dense(16, kernel_regularizer=tf.keras.regularizers.l2(0.01), activation='relu'),\n",
        "  layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l2(0.01), activation='relu'),\n",
        "  layers.Dropout(0.2),\n",
        "  \n",
        "  layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_ds,\n",
        "          validation_data=val_ds,\n",
        "          epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "6nNIlICVAqDP"
      },
      "outputs": [],
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "colab_type": "code",
        "id": "iF3r3p5Qnv9H",
        "outputId": "8c7ee996-e41c-4218-d0ce-89d8bd9e5347"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print(\"Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "FP5NfLE3BuB3"
      },
      "outputs": [],
      "source": [
        "## Train vs Val 'accuracy' and 'loss'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "colab_type": "code",
        "id": "Y_JiEjKDBsiZ",
        "outputId": "1ac1363c-33e4-4dca-babb-55f6813717f4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "epochs = range(20)\n",
        "\n",
        "plt.title('Accuracy')\n",
        "plt.plot(epochs,  history.history['accuracy'], color='blue', label='Train')\n",
        "plt.plot(epochs, history.history['val_accuracy'], color='orange', label='Val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "_ = plt.figure()\n",
        "plt.title('Loss')\n",
        "plt.plot(epochs, history.history['loss'], color='blue', label='Train')\n",
        "plt.plot(epochs, history.history['val_loss'], color='orange', label='Val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "XPnR3OuIHiVi"
      },
      "outputs": [],
      "source": [
        "# Problem Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "kxyQsDu9HxP_"
      },
      "outputs": [],
      "source": [
        "## Load and preprocess test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "colab_type": "code",
        "id": "h_K5RuiTt8D9",
        "outputId": "0dca7cbe-c67d-471a-c932-1f4664552077"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv('drive/My Drive/collab data/titanic/test.csv')\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "colab_type": "code",
        "id": "uJZChzrTuPV2",
        "outputId": "6aabdd3d-7e76-4c18-c41f-78e78023425a"
      },
      "outputs": [],
      "source": [
        "test_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zmkjQfcXuR7C"
      },
      "outputs": [],
      "source": [
        "mean_value = round(data['Age'].mean())\n",
        "mean_value1 = data['Fare'].mean()\n",
        "\n",
        "value = {'Age': mean_value, 'Fare': mean_value1}\n",
        "test_data.fillna(value=value,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6Xxpisofv9CZ"
      },
      "outputs": [],
      "source": [
        "test_data.dropna(axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "LOmagsGrH-ga"
      },
      "outputs": [],
      "source": [
        "## Input function for test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "itERkfi0vYnq"
      },
      "outputs": [],
      "source": [
        "def test_input_fn(features, batch_size=256):\n",
        "    \"\"\"An input function for prediction.\"\"\"\n",
        "    # Convert the inputs to a Dataset without labels.\n",
        "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IUlJqxejvhQ5"
      },
      "outputs": [],
      "source": [
        "test_predict = test_input_fn(dict(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "9C_FzoyFIHTP"
      },
      "outputs": [],
      "source": [
        "## Prediction \n",
        "Predicting proability "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "P2Gf0xihvhwV"
      },
      "outputs": [],
      "source": [
        "predicted_ar=model.predict(test_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "vNDtvE5kISGn"
      },
      "outputs": [],
      "source": [
        "### Prediction DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "colab_type": "code",
        "id": "54RB-K3PwQmf",
        "outputId": "d919ddba-91d9-4117-b17b-c6333681a400"
      },
      "outputs": [],
      "source": [
        "predict_df = test_data[['PassengerId']]\n",
        "predict_df['Survived'] = predicted_ar\n",
        "predict_df['Survived'] = predict_df['Survived'].apply(lambda x: 1 if x>=.5 else 0) #converting probability into class\n",
        "predict_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "AgBl4uQIKa1s"
      },
      "outputs": [],
      "source": [
        "# End"
      ]
    }
  ]
}